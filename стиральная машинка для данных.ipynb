{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random as rnd\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from missforest import MissForest\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pyreadr.read_r(\"spark_23.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result[\"spark_23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Код основного вида деятельности (SPLIT)\"] = df[\"Код основного вида деятельности\"].apply(lambda x: x.split(\".\")[0] if pd.notna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecoverMissingData:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, cat_cols: list[str], num_cols: list[str], share_of_missing: float):\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        self.df = df\n",
    "        self.num_cols = num_cols # IF FILLING MISSING VALUES BY ROWS INPUT COLUMN NAMES OF ONE VARIABLE\n",
    "        self.cat_cols = cat_cols # INPUT ONLY TWO OR THREE CATEGORICAL COLUMNS\n",
    "        self.cols = cat_cols + num_cols\n",
    "\n",
    "        self.num_of_cats = len(cat_cols)\n",
    "\n",
    "        problist = [0 if share_of_missing * 100 > i else 1 for i in range(100)]\n",
    "        np.random.shuffle(problist)\n",
    "        self.problist = problist\n",
    "\n",
    "# ===========================================================================================================        \n",
    "# КОЛОНОЧНЫЕ МЕТОДЫ\n",
    "\n",
    "    def TEST_fill_with_mean_by_column(self):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        fix_df = pd.DataFrame()\n",
    "        comp_df = pd.DataFrame()\n",
    "        cat_cols = self.cat_cols\n",
    "\n",
    "        if self.num_of_cats == 2:\n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "\n",
    "                    fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j)]\n",
    "                    comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j)]\n",
    "                        \n",
    "                    for num_col in self.num_cols:\n",
    "                        m = np.nanmean(fix_in_loop_df[num_col])\n",
    "                        fix_in_loop_df[num_col] = fix_in_loop_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "                    fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                    comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "\n",
    "        elif self.num_of_cats == 3: \n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "                    for k in set(del_df[cat_cols[2]].to_list()):\n",
    "\n",
    "                        fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j) & (del_df[cat_cols[2]] == k)]\n",
    "                        comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j) & (new_df[cat_cols[2]] == k)]\n",
    "                            \n",
    "                        for num_col in self.num_cols:\n",
    "                            m = np.nanmean(fix_in_loop_df[num_col])\n",
    "                            fix_in_loop_df[num_col] = fix_in_loop_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "                        fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                        comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "        else: \n",
    "            raise ValueError(\"number of columns with categorical data must be 2 or 3\")\n",
    "\n",
    "\n",
    "        for num_col in tqdm.tqdm(self.num_cols):\n",
    "            m = np.nanmean(fix_df[num_col].to_list())\n",
    "            fix_df[num_col] = fix_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "\n",
    "        self.comp_df = comp_df.sort_index()\n",
    "        self.fix_df = fix_df.sort_index()\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================        \n",
    "\n",
    "    def TEST_fill_with_median_by_column(self):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        fix_df = pd.DataFrame()\n",
    "        comp_df = pd.DataFrame()\n",
    "        cat_cols = self.cat_cols\n",
    "\n",
    "        if self.num_of_cats == 2:\n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "\n",
    "                    fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j)]\n",
    "                    comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j)]\n",
    "                        \n",
    "                    for num_col in self.num_cols:\n",
    "                        m = np.nanmedian(fix_in_loop_df[num_col])\n",
    "                        fix_in_loop_df[num_col] = fix_in_loop_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "                    fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                    comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "\n",
    "        elif self.num_of_cats == 3: \n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "                    for k in set(del_df[cat_cols[2]].to_list()):\n",
    "\n",
    "                        fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j) & (del_df[cat_cols[2]] == k)]\n",
    "                        comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j) & (new_df[cat_cols[2]] == k)]\n",
    "                            \n",
    "                        for num_col in self.num_cols:\n",
    "                            m = np.nanmedian(fix_in_loop_df[num_col])\n",
    "                            fix_in_loop_df[num_col] = fix_in_loop_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "                        fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                        comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "        else: \n",
    "            raise ValueError(\"number of columns with categorical data must be 2 or 3\")\n",
    "\n",
    "        for num_col in tqdm.tqdm(self.num_cols):\n",
    "            m = np.nanmedian(fix_df[num_col].to_list())\n",
    "            fix_df[num_col] = fix_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "\n",
    "        self.comp_df = comp_df.sort_index()\n",
    "        self.fix_df = fix_df.sort_index()\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================  \n",
    "# ПОСТРОЧНЫЕ МЕТОДЫ      \n",
    "\n",
    "    def TEST_fill_with_mean_by_row(self):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        col_m = np.mean(\n",
    "            [j for i in self.num_cols for j in new_df[i].to_list()]\n",
    "        )\n",
    "        \n",
    "        np.random.seed(42)\n",
    "\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        self.comp_df = new_df\n",
    "        fix_dict = {}\n",
    "\n",
    "        del_dict = del_df.to_dict(\"index\")\n",
    "\n",
    "        for i in tqdm.tqdm(del_dict.keys()):\n",
    "\n",
    "            m = np.nanmean([del_dict[i][j] for j in self.num_cols]) \n",
    "\n",
    "            if pd.isna(m):\n",
    "                m = col_m\n",
    "\n",
    "            in_loop_dict = {i: {}}\n",
    "\n",
    "            for col in self.cols:\n",
    "                if pd.notna(del_dict[i][col]):\n",
    "                    in_loop_dict[i][col] = del_dict[i][col]\n",
    "                else:\n",
    "                    in_loop_dict[i][col] = m\n",
    "\n",
    "            fix_dict[i] = in_loop_dict[i]\n",
    "\n",
    "\n",
    "        self.fix_df =  pd.DataFrame.from_dict(fix_dict, orient=\"index\")\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================  \n",
    "\n",
    "    def TEST_fill_with_median_by_row(self):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        col_m = np.median(\n",
    "            [j for i in self.num_cols for j in new_df[i].to_list()]\n",
    "        )\n",
    "        \n",
    "        np.random.seed(42)\n",
    "\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        self.comp_df = new_df\n",
    "        fix_dict = {}\n",
    "\n",
    "        del_dict = del_df.to_dict(\"index\")\n",
    "\n",
    "        for i in tqdm.tqdm(del_dict.keys()):\n",
    "\n",
    "            m = np.nanmedian([del_dict[i][j] for j in self.num_cols]) \n",
    "\n",
    "            if pd.isna(m):\n",
    "                m = col_m\n",
    "\n",
    "            in_loop_dict = {i: {}}\n",
    "\n",
    "            for col in self.cols:\n",
    "                if pd.notna(del_dict[i][col]):\n",
    "                    in_loop_dict[i][col] = del_dict[i][col]\n",
    "                else:\n",
    "                    in_loop_dict[i][col] = m\n",
    "\n",
    "            fix_dict[i] = in_loop_dict[i]\n",
    "\n",
    "\n",
    "        self.fix_df =  pd.DataFrame.from_dict(fix_dict, orient=\"index\")\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================  \n",
    "# МЕТОДЫ НА ОСНОВЕ МО\n",
    "\n",
    "    def TEST_KNN_Imputer(self, n_neighbours: int, strategy_for_exceptions: str):\n",
    "\n",
    "        if strategy_for_exceptions not in [\"mean\", \"median\"]:\n",
    "            raise ValueError(\"Can only take 'median' or 'mean' as arguments.\")\n",
    "        if type(n_neighbours) != int:\n",
    "            raise TypeError(\"n_neighbours must be 'int'\")\n",
    "\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        fix_df = pd.DataFrame()\n",
    "        comp_df = pd.DataFrame()\n",
    "        cat_cols = self.cat_cols\n",
    "\n",
    "        if self.num_of_cats == 1:\n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "\n",
    "                    fix_in_loop_df = del_df[del_df[cat_cols[0]] == i]\n",
    "                    comp_in_loop_df = new_df[new_df[cat_cols[0]] == i]\n",
    "\n",
    "                    try:\n",
    "                        imputed_values = KNNImputer(n_neighbors=n_neighbours).fit_transform(fix_in_loop_df[self.num_cols])\n",
    "                        imputed_values_index = fix_in_loop_df[self.num_cols].index\n",
    "                        fix_in_loop_df[self.num_cols] = pd.DataFrame(imputed_values, columns=self.num_cols, index=imputed_values_index)  \n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                    comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "\n",
    "        elif self.num_of_cats == 2:\n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "\n",
    "                    fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j)]\n",
    "                    comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j)]\n",
    "\n",
    "                    try:\n",
    "                        imputed_values = KNNImputer(n_neighbors=n_neighbours).fit_transform(fix_in_loop_df[self.num_cols])\n",
    "                        imputed_values_index = fix_in_loop_df[self.num_cols].index\n",
    "                        fix_in_loop_df[self.num_cols] = pd.DataFrame(imputed_values, columns=self.num_cols, index=imputed_values_index)  \n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                    comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "\n",
    "        elif self.num_of_cats == 3:\n",
    "            for i in tqdm.tqdm(list(set(del_df[cat_cols[0]].to_list()))):\n",
    "                for j in set(del_df[cat_cols[1]].to_list()):\n",
    "                    for k in set(del_df[cat_cols[2]].to_list()):\n",
    "\n",
    "                        fix_in_loop_df = del_df[(del_df[cat_cols[0]] == i) & (del_df[cat_cols[1]] == j) & (del_df[cat_cols[2]] == k)]\n",
    "                        comp_in_loop_df = new_df[(new_df[cat_cols[0]] == i) & (new_df[cat_cols[1]] == j) & (new_df[cat_cols[2]] == k)]\n",
    "\n",
    "                        try:\n",
    "                            imputed_values = KNNImputer(n_neighbors=n_neighbours).fit_transform(fix_in_loop_df[self.num_cols])\n",
    "                            imputed_values_index = fix_in_loop_df[self.num_cols].index\n",
    "                            fix_in_loop_df[self.num_cols] = pd.DataFrame(imputed_values, columns=self.num_cols, index=imputed_values_index)  \n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                        fix_df = pd.concat([fix_df, fix_in_loop_df], ignore_index=False)\n",
    "                        comp_df = pd.concat([comp_df, comp_in_loop_df], ignore_index=False)\n",
    "\n",
    "        if strategy_for_exceptions == \"mean\":\n",
    "            m_func = np.nanmean\n",
    "        elif strategy_for_exceptions == \"median\":\n",
    "            m_func = np.nanmedian\n",
    "\n",
    "        for num_col in tqdm.tqdm(self.num_cols):\n",
    "            m = m_func(fix_df[num_col].to_list())\n",
    "            fix_df[num_col] = fix_df[num_col].apply(lambda x: x if pd.notna(x) else m)\n",
    "\n",
    "        self.comp_df = comp_df.sort_index()\n",
    "        self.fix_df = fix_df.sort_index()\n",
    "        self.del_df = del_df\n",
    "        pass \n",
    "\n",
    "# ===========================================================================================================     \n",
    "\n",
    "    def TEST_KNN_wrapper(self, n_neighbours: int):\n",
    "\n",
    "        if type(n_neighbours) != int:\n",
    "            raise TypeError(\"n_neighbours must be 'int'\")\n",
    "        \n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        print(\"randomly deleting values\")\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        fix_df = pd.DataFrame()\n",
    "        comp_df = pd.DataFrame()\n",
    "\n",
    "        print(\"imputing missing values\")\n",
    "        imputed_values = KNNImputer(n_neighbors=n_neighbours).fit_transform(del_df[self.num_cols])\n",
    "        fix_df[self.num_cols] = pd.DataFrame(imputed_values, columns=self.num_cols)\n",
    "\n",
    "        self.fix_df = fix_df\n",
    "        self.comp_df = new_df[self.num_cols]\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================    \n",
    "\n",
    "    def TEST_Miss_Forest(self, classifier, regressor, early_stopping: bool, verbose: int, max_iter: int):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        print(\"randomly deleting values\")\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        fix_df = pd.DataFrame()\n",
    "        comp_df = pd.DataFrame()\n",
    "\n",
    "        print(\"encoding categorical values\")\n",
    "        for i in self.cat_cols:\n",
    "            encoded_col = pd.DataFrame({i: LabelEncoder().fit_transform(del_df[i])})\n",
    "            del_df[i], comp_df[i] = encoded_col, encoded_col\n",
    "\n",
    "\n",
    "\n",
    "        mf = MissForest(clf=classifier, rgr=regressor, categorical=self.cat_cols, early_stopping=early_stopping, verbose=verbose, max_iter=max_iter)\n",
    "        imputed_values = mf.fit_transform(del_df[self.cols])\n",
    "        fix_df[self.cols] = pd.DataFrame(fix_df, columns=self.cols)\n",
    "\n",
    "        self.fix_df = fix_df\n",
    "        self.comp_df = new_df\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================    \n",
    "\n",
    "    def TEST_Iterative_Imputer(self, estimator, missing_value, max_iter: int, n_nearest_features: int, tol: float, verbose: int, initial_strategy: str):\n",
    "\n",
    "        new_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "        del_df = self.df[self.cols].dropna().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        print(\"randomly deleting values\")\n",
    "        for col in self.num_cols:\n",
    "\n",
    "            del_df[col] = del_df[col].apply(lambda x: np.nan if np.random.choice(self.problist) == 0 else x)\n",
    "\n",
    "        imputer = IterativeImputer(\n",
    "            estimator=estimator,\n",
    "            missing_values=missing_value,\n",
    "            tol=tol,\n",
    "            n_nearest_features=n_nearest_features,\n",
    "            verbose=verbose,\n",
    "            initial_strategy=initial_strategy,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        imputed_values = imputer.fit_transform(del_df[self.num_cols])\n",
    "\n",
    "\n",
    "        self.fix_df = pd.DataFrame(imputed_values, columns=self.num_cols)\n",
    "        self.comp_df = new_df[self.num_cols]\n",
    "        self.del_df = del_df\n",
    "        pass\n",
    "\n",
    "# ===========================================================================================================       \n",
    "   \n",
    "    def TEST_error(self):\n",
    "            \n",
    "        # bool_df = self.comp_df == self.fix_df\n",
    "\n",
    "        coor_list = []\n",
    "\n",
    "        for num_col in self.num_cols:\n",
    "            for y in range(self.del_df.shape[0]):\n",
    "\n",
    "                if pd.isna(self.del_df.loc[y, num_col]):\n",
    "                    coor_list.append((y, num_col))\n",
    "\n",
    "        true_list = []\n",
    "        fill_list = []\n",
    "\n",
    "        for coor in tqdm.tqdm(coor_list):\n",
    "\n",
    "            comp_df_value = self.comp_df.loc[*coor]\n",
    "            true_list.append(comp_df_value)\n",
    "\n",
    "            fix_df_value = self.fix_df.loc[*coor]\n",
    "            fill_list.append(fix_df_value)\n",
    "\n",
    "        print(root_mean_squared_error(true_list, fill_list))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_of_misssing = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# КОЛОНОЧНЫЕ МЕТОДЫ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СРЕДНЕЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.55it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_fill = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[\"Код основного вида деятельности (SPLIT)\", \"Размер компании\"],\n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "mean_fill.TEST_fill_with_mean_by_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 67718.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724525045.1754906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:29<00:00,  3.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.97it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_fill = RecoverMissingData(\n",
    "    df=df, \n",
    "    cat_cols=[\"Регион регистрации\", \"Размер компании\", \"Код основного вида деятельности (SPLIT)\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "mean_fill.TEST_fill_with_mean_by_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 71295.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810120183.629303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МЕДИАНА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.42it/s]\n"
     ]
    }
   ],
   "source": [
    "median_fill = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[\"Код основного вида деятельности (SPLIT)\", \"Размер компании\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "median_fill.TEST_fill_with_median_by_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 57999.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725400856.1779954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "median_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:27<00:00,  3.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.50it/s]\n"
     ]
    }
   ],
   "source": [
    "median_fill = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[\"Регион регистрации\", \"Код основного вида деятельности (SPLIT)\", \"Размер компании\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "median_fill.TEST_fill_with_median_by_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 71173.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795545167.2982346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "median_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОСТРОЧНЫЕ МЕТОДЫ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СРЕДНЕЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111674/111674 [00:02<00:00, 37443.73it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_by_row_fill = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ") \n",
    "\n",
    "mean_by_row_fill.TEST_fill_with_mean_by_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 60483.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148610968.312059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_by_row_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МЕДИАНА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111674/111674 [00:03<00:00, 31317.74it/s]\n"
     ]
    }
   ],
   "source": [
    "median_by_row_fill = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing \n",
    ") \n",
    "\n",
    "median_by_row_fill.TEST_fill_with_median_by_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 70006.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406891574.3045145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "median_by_row_fill.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# МЕТОДЫ НА ОСНОВЕ МО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ К-БЛИЖАЙШИХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### К-БЛИЖАЙШИХ C РАЗБИЕНИЕМ НА КАТЕГОРИИ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:06<00:00, 12.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.32it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_with_median = RecoverMissingData(\n",
    "    df=df, \n",
    "    cat_cols=[\"Регион регистрации\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    " \n",
    "knn_with_median.TEST_KNN_Imputer(n_neighbours=10, strategy_for_exceptions=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 70256.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561696727.7913239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knn_with_median.TEST_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 17.64it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_with_median = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[\"Код основного вида деятельности (SPLIT)\", \"Размер компании\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing    \n",
    ") \n",
    "\n",
    "knn_with_median.TEST_KNN_Imputer(n_neighbours=3, strategy_for_exceptions=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 74836.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399920947.3690318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knn_with_median.TEST_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:59<00:00,  4.28s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.35it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_with_median = RecoverMissingData(\n",
    "    df=df, \n",
    "    cat_cols=[\"Регион регистрации\", \"Код основного вида деятельности (SPLIT)\", \"Размер компании\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ") \n",
    "\n",
    "knn_with_median.TEST_KNN_Imputer(n_neighbours=1, strategy_for_exceptions=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21216/21216 [00:00<00:00, 70692.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731938360.0562853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knn_with_median.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### К-БЛИЖАЙШИХ БЕЗ РАЗБИЕНИЯ НА КАТЕГОРИИ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly deleting values\n",
      "imputing missing values\n"
     ]
    }
   ],
   "source": [
    "knn = RecoverMissingData(\n",
    "    df=df, \n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ") \n",
    "\n",
    "knn.TEST_KNN_wrapper(n_neighbours=5)\n",
    "# approximate runtime for ~106000x4 dataframe: 8:30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 44012.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311947246.1854263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knn.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОТЕРЯННЫЙ(?) ЛЕС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[\"Регион регистрации\", \"Код основного вида деятельности (SPLIT)\", \"Размер компании\"], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ") \n",
    "\n",
    "mf.TEST_Miss_Forest(\n",
    "    classifier=RandomForestClassifier(n_jobs=-1), \n",
    "    regressor=RandomForestRegressor(n_jobs=-1), \n",
    "    early_stopping=True, \n",
    "    verbose=1, \n",
    "    max_iter=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ИТЕРАТИВНОЕ ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ РАЗЛИЧНЫХ ОЦЕНЩИКОВ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИТЕРАТИВНОЕ ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ ГРАДИЕНТНОГО БУСТИНГА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly deleting values\n",
      "[IterativeImputer] Completing matrix with shape (111674, 4)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.69\n",
      "[IterativeImputer] Change: 38408891127.44298, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 1.35\n",
      "[IterativeImputer] Change: 12973671919.16134, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 1.95\n",
      "[IterativeImputer] Change: 1405984590.627125, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 2.57\n",
      "[IterativeImputer] Change: 586398550.4316025, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 3.18\n",
      "[IterativeImputer] Change: 613125167.076992, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 3.81\n",
      "[IterativeImputer] Change: 503206227.1752751, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 4.41\n",
      "[IterativeImputer] Change: 763542455.4363327, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 5.04\n",
      "[IterativeImputer] Change: 430802882.1377888, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 5.64\n",
      "[IterativeImputer] Change: 428011380.13334227, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 6.26\n",
      "[IterativeImputer] Change: 445184720.41659546, scaled tolerance: 47314016.300000004 \n"
     ]
    }
   ],
   "source": [
    "gb = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "hgbr = HistGradientBoostingRegressor(\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.TEST_Iterative_Imputer(\n",
    "    estimator=hgbr,\n",
    "    missing_value=np.nan,\n",
    "    n_nearest_features=3,\n",
    "    max_iter=100,\n",
    "    tol=0.0001,\n",
    "    verbose=2,\n",
    "    initial_strategy=\"median\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 74243.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497246843.0283296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gb.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИТЕРАТИВНОЕ ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ СЛУЧАЙНОГО ЛЕСА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly deleting values\n",
      "[IterativeImputer] Completing matrix with shape (111674, 4)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 71.24\n",
      "[IterativeImputer] Change: 58106674100.0, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 143.75\n",
      "[IterativeImputer] Change: 5391218150.0, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 217.20\n",
      "[IterativeImputer] Change: 3192124380.0, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 291.58\n",
      "[IterativeImputer] Change: 2568352020.0, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 364.28\n",
      "[IterativeImputer] Change: 2918319814.619999, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 444.11\n",
      "[IterativeImputer] Change: 3097893384.619999, scaled tolerance: 47314016.300000004 \n"
     ]
    }
   ],
   "source": [
    "rf = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rf.TEST_Iterative_Imputer(\n",
    "    estimator=rfr,\n",
    "    missing_value=np.nan,\n",
    "    n_nearest_features=3,\n",
    "    max_iter=50,\n",
    "    tol=0.0001,\n",
    "    verbose=2,\n",
    "    initial_strategy=\"median\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИТЕРАТИВНОЕ ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ ЛИНЕЙНОГО МЕТОДА ОПОРНЫХ ВЕКТОРОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly deleting values\n",
      "[IterativeImputer] Completing matrix with shape (111674, 4)\n",
      "[IterativeImputer] Change: 71570588141.19485, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Change: 10594018734.230152, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Change: 689513757.634265, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Change: 151838622.42597485, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Change: 37667252.91960716, scaled tolerance: 47314016.300000004 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "lsv = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "lsvr = LinearSVR(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lsv.TEST_Iterative_Imputer(\n",
    "    estimator=lsvr,\n",
    "    missing_value=np.nan,\n",
    "    n_nearest_features=3,\n",
    "    max_iter=100,\n",
    "    tol=0.0001,\n",
    "    verbose=1,\n",
    "    initial_strategy=\"median\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 66794.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686091734.083398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lsv.TEST_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИТЕРАТИВНОЕ ЗАПОЛНЕНИЕ С ИСПОЛЬЗОВАНИЕМ К-БЛИЖАЙШИХ СОСЕДЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly deleting values\n",
      "[IterativeImputer] Completing matrix with shape (111674, 4)\n",
      "[IterativeImputer] Change: 44439533100.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5750283700.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5748791400.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5469151600.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5411445500.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5395528800.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 2607319200.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 4251017900.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 5401608700.0, scaled tolerance: 473140.163 \n",
      "[IterativeImputer] Change: 2607319200.0, scaled tolerance: 473140.163 \n"
     ]
    }
   ],
   "source": [
    "knn = RecoverMissingData(\n",
    "    df=df,\n",
    "    cat_cols=[], \n",
    "    num_cols=[\"2019, Доходы, RUB\", \"2020, Доходы, RUB\", \"2021, Доходы, RUB\", \"2022, Доходы, RUB\"],\n",
    "    share_of_missing=share_of_misssing\n",
    ")\n",
    "\n",
    "knnr = KNeighborsRegressor(\n",
    "    n_neighbors=10,\n",
    "    algorithm=\"kd_tree\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn.TEST_Iterative_Imputer(\n",
    "    estimator=knnr,\n",
    "    missing_value=np.nan,\n",
    "    n_nearest_features=3,\n",
    "    max_iter=1000,\n",
    "    tol=0.000001,\n",
    "    verbose=1,\n",
    "    initial_strategy=\"median\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22279/22279 [00:00<00:00, 63913.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335009684.37897164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knn.TEST_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
